// Will be responsible for creating both the offer and answer, handling ICE candidates, 
// and setting up the peer-to-peer WebRTC connection.

// Connect to the signaling server via Socket.IO
const socket = io();

// Get the video element to display the remote stream
const remoteVideo = document.getElementById("remoteVideo");

// Create a new RTCPeerConnection with STUN server configuration for NAT traversal
let pc = new RTCPeerConnection({
  iceServers: [{ urls: "stun:stun.l.google.com:19302" }]
});

// Log connection state changes
pc.onconnectionstatechange = () => {
  console.log("Connection state:", pc.connectionState);
};

// Log ICE connection state changes
pc.oniceconnectionstatechange = () => {
  console.log("ICE connection state:", pc.iceConnectionState);
};

// Handle ICE candidates generated by this client and send them to the signaling server
pc.onicecandidate = (event) => {
  if (event.candidate) {
    console.log("Local ICE candidate:", event.candidate);
    // Send ICE candidate to the signaling server to relay to the other peer
    socket.emit("candidate", event.candidate);
  }
};

// When a remote track (media stream) is received, display it in the video element
pc.ontrack = (event) => {
  console.log("Received remote track:", event.streams[0]);
  remoteVideo.srcObject = event.streams[0];
};

// Listen for an offer from the signaling server
socket.on("offer", async (offer) => {
  // Set the remote description to the received offer
  await pc.setRemoteDescription(new RTCSessionDescription(offer));

  // Create an answer to send back to the other peer
  const answer = await pc.createAnswer();
  await pc.setLocalDescription(answer);

  // Send the answer to the signaling server
  socket.emit("answer", answer);
});

// Listen for an answer from the signaling server (sent when the other client responds to the offer)
socket.on("answer", async (answer) => {
  // Set the remote description to the received answer
  await pc.setRemoteDescription(new RTCSessionDescription(answer));
});

// Listen for ICE candidates from the signaling server
socket.on("candidate", async (candidate) => {
  console.log("Received ICE candidate:", candidate);
  // Add the received ICE candidate to establish a network path with the other peer
  await pc.addIceCandidate(new RTCIceCandidate(candidate));
});

// Function to start the WebRTC connection by creating an offer
async function startConnection() {
  console.log("Starting connection and requesting local media...");

  // Check if the browser supports navigator.mediaDevices and getUserMedia
  if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
    console.error("getUserMedia is not supported in this browser.");
    // Exit the function if getUserMedia is not available
    return;
  }

  try {
    // Request access to the user's camera and microphone
    const stream = await navigator.mediaDevices.getUserMedia({ video: true, audio: true });
    console.log("Local media stream:", stream); // Log the obtained media stream

    // Add each track from the media stream to the RTCPeerConnection
    stream.getTracks().forEach(track => pc.addTrack(track, stream));

    // Create an offer to initiate the WebRTC connection
    const offer = await pc.createOffer();
    console.log("Created offer:", offer); // Log the created offer (SDP)

    // Set the local description to the created offer
    await pc.setLocalDescription(offer);

    // Send the offer to the signaling server to be forwarded to the other peer
    socket.emit("offer", offer);
  } catch (error) {
    // Handle any errors that occur when trying to access media devices
    console.error("Error accessing media devices.", error);
  }
}

// Start the WebRTC connection process
startConnection();

